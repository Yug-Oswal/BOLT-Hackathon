{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4f71adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51929227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.14.0'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "21a37e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogicalDevice(name='/device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_logical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f53b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow_datasets as tfds\n",
    "import keras_nlp\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93d83586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8748ac8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn, unpatch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e34d385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/tt247gpu2/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7213f439",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./data/goemotions1.csv')\n",
    "df2 = pd.read_csv('./data/goemotions2.csv')\n",
    "df3 = pd.read_csv('./data/goemotions3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cd9890b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text',\n",
       " 'id',\n",
       " 'author',\n",
       " 'subreddit',\n",
       " 'link_id',\n",
       " 'parent_id',\n",
       " 'created_utc',\n",
       " 'rater_id',\n",
       " 'example_very_unclear',\n",
       " 'admiration',\n",
       " 'amusement',\n",
       " 'anger',\n",
       " 'annoyance',\n",
       " 'approval',\n",
       " 'caring',\n",
       " 'confusion',\n",
       " 'curiosity',\n",
       " 'desire',\n",
       " 'disappointment',\n",
       " 'disapproval',\n",
       " 'disgust',\n",
       " 'embarrassment',\n",
       " 'excitement',\n",
       " 'fear',\n",
       " 'gratitude',\n",
       " 'grief',\n",
       " 'joy',\n",
       " 'love',\n",
       " 'nervousness',\n",
       " 'optimism',\n",
       " 'pride',\n",
       " 'realization',\n",
       " 'relief',\n",
       " 'remorse',\n",
       " 'sadness',\n",
       " 'surprise',\n",
       " 'neutral']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55a75ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.loc[ : , ['text', 'admiration',\n",
    " 'amusement',\n",
    " 'anger',\n",
    " 'annoyance',\n",
    " 'approval',\n",
    " 'caring',\n",
    " 'confusion',\n",
    " 'curiosity',\n",
    " 'desire',\n",
    " 'disappointment',\n",
    " 'disapproval',\n",
    " 'disgust',\n",
    " 'embarrassment',\n",
    " 'excitement',\n",
    " 'fear',\n",
    " 'gratitude',\n",
    " 'grief',\n",
    " 'joy',\n",
    " 'love',\n",
    " 'nervousness',\n",
    " 'optimism',\n",
    " 'pride',\n",
    " 'realization',\n",
    " 'relief',\n",
    " 'remorse',\n",
    " 'sadness',\n",
    " 'surprise',\n",
    " 'neutral']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e77a23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.loc[ : , ['text', 'admiration',\n",
    " 'amusement',\n",
    " 'anger',\n",
    " 'annoyance',\n",
    " 'approval',\n",
    " 'caring',\n",
    " 'confusion',\n",
    " 'curiosity',\n",
    " 'desire',\n",
    " 'disappointment',\n",
    " 'disapproval',\n",
    " 'disgust',\n",
    " 'embarrassment',\n",
    " 'excitement',\n",
    " 'fear',\n",
    " 'gratitude',\n",
    " 'grief',\n",
    " 'joy',\n",
    " 'love',\n",
    " 'nervousness',\n",
    " 'optimism',\n",
    " 'pride',\n",
    " 'realization',\n",
    " 'relief',\n",
    " 'remorse',\n",
    " 'sadness',\n",
    " 'surprise',\n",
    " 'neutral']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "695b1f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.loc[ : , ['text', 'admiration',\n",
    " 'amusement',\n",
    " 'anger',\n",
    " 'annoyance',\n",
    " 'approval',\n",
    " 'caring',\n",
    " 'confusion',\n",
    " 'curiosity',\n",
    " 'desire',\n",
    " 'disappointment',\n",
    " 'disapproval',\n",
    " 'disgust',\n",
    " 'embarrassment',\n",
    " 'excitement',\n",
    " 'fear',\n",
    " 'gratitude',\n",
    " 'grief',\n",
    " 'joy',\n",
    " 'love',\n",
    " 'nervousness',\n",
    " 'optimism',\n",
    " 'pride',\n",
    " 'realization',\n",
    " 'relief',\n",
    " 'remorse',\n",
    " 'sadness',\n",
    " 'surprise',\n",
    " 'neutral']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b04618a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 29)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a10bcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.concat([df1, df2, df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4d676cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211225, 29)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e85bb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = total_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ceaf579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211225, 29)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62ac15a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fb0aca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    I have, and now that you mention it, I think t...\n",
       "11    I wanted to downvote this, but it's not your f...\n",
       "12                                BUT IT'S HER TURN! /s\n",
       "13                                         That is odd.\n",
       "14                                    Build a wall? /jk\n",
       "15    I appreciate it, that's good to know. I hope I...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df['text'][10:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "231e54fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['text'] = total_df['text'].apply(clean_text)\n",
    "total_df['text'] = total_df['text'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8a84357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10              mention think thats triggered nostalgia\n",
       "11                          wanted downvote fault homie\n",
       "12                                                 turn\n",
       "13                                                  odd\n",
       "14                                        build wall jk\n",
       "15    appreciate thats good know hope ill apply know...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df['text'][10:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a84df786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32388 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 50000\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(total_df['text'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42d67fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (211225, 250)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(total_df['text'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8590d08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'admiration', 'amusement', 'anger', 'annoyance', 'approval',\n",
       "       'caring', 'confusion', 'curiosity', 'desire', 'disappointment',\n",
       "       'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear',\n",
       "       'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride',\n",
       "       'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7feb3255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (211225, 28)\n"
     ]
    }
   ],
   "source": [
    "Y = total_df.loc[ : , ['admiration', 'amusement', 'anger', 'annoyance', 'approval',\n",
    "       'caring', 'confusion', 'curiosity', 'desire', 'disappointment',\n",
    "       'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear',\n",
    "       'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride',\n",
    "       'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']].astype(np.float32).values\n",
    "print('Shape of label tensor:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0222793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190102,) (190102, 28)\n",
      "(21123,) (21123, 28)\n"
     ]
    }
   ],
   "source": [
    "# Replacing X in train_test_split with total_df['text'] since we are now fine-tuning, model will preprocess\n",
    "# text in a preset algorithm\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(total_df['text'],Y, test_size = 0.10, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c867a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    That game hurt.\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df['text'][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adf8ea4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b6666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(MAX_SEQUENCE_LENGTH, ))\n",
    "x = Embedding(MAX_NB_WORDS, EMBEDDING_DIM)(input)\n",
    "x = SpatialDropout1D(0.2)(x)\n",
    "x = LSTM(100, dropout=0.2, recurrent_dropout=0.2)(x)\n",
    "output = Dense(28, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1fd1f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_CE_Loss(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def call(self, y_true, y_pred):        \n",
    "        log_y_pred = tf.math.log(y_pred)\n",
    "        element_wise = -tf.math.multiply_no_nan(x=log_y_pred, y=y_true)\n",
    "        return tf.reduce_mean(tf.reduce_sum(element_wise,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e8215c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse categorical cross entropy has an internal error\n",
    "# therefore, defined my own custom implementation of cross entropy\n",
    "model.compile(loss=My_CE_Loss(), optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d5928d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 250)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 250, 100)          5000000   \n",
      "                                                                 \n",
      " spatial_dropout1d (Spatial  (None, 250, 100)          0         \n",
      " Dropout1D)                                                      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               80400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 28)                2828      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5083228 (19.39 MB)\n",
      "Trainable params: 5083228 (19.39 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60daab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=10\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3eed9f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train1 = tf.convert_to_tensor(Y_train, dtype=tf.float32)\n",
    "Y_test1 = tf.convert_to_tensor(Y_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb978f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2674/2674 [==============================] - 2128s 795ms/step - loss: 2.8721 - accuracy: 0.3641 - val_loss: 2.6321 - val_accuracy: 0.3964\n",
      "Epoch 2/10\n",
      " 618/2674 [=====>........................] - ETA: 27:44 - loss: 2.5049 - accuracy: 0.4167"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6510/460676357.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(X_train, Y_train1, epochs=EPOCHS, batch_size=BATCH_SIZE,validation_split=0.1,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1781\u001b[0m                         ):\n\u001b[1;32m   1782\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1783\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    868\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1263\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mflat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;34m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1480\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train1, epochs=EPOCHS, batch_size=BATCH_SIZE,validation_split=0.1,\n",
    "                    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "322eb3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since training a model from scratch is taking a lot of compute and time\n",
    "# Now setting up a preprocess-encode-decode-output pipeline for fine-tuning\n",
    "preprocessor = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')\n",
    "encoder = hub.KerasLayer(\n",
    "   'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/2',\n",
    "   trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef29d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "x = preprocessor(txt)\n",
    "x = encoder(x)['pooled_output']\n",
    "x = tf.keras.layers.Dropout(0.1)(x)\n",
    "x = tf.keras.layers.Dense(Y_train1.shape[1], activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=[txt], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73ecfa99-264a-400f-9a95-09c6eb400b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "emotions = urllib.request.urlopen(\n",
    "   'https://raw.githubusercontent.com/google-research/google-research'\n",
    "   '/master/goemotions/data/emotions.txt').read().decode('utf8').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7480147-d0c3-438a-a4c4-42487b0ba4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(split, batch_size=128):\n",
    " def one_hot_encode(x):\n",
    "   vec = tf.stack([x[emotion] for emotion in emotions], 0)\n",
    "   return x['comment_text'], tf.cast(vec, tf.uint8)\n",
    "     \n",
    " ds = tfds.load('goemotions', split=split)\n",
    " ds = ds.map(one_hot_encode, num_parallel_calls=tf.data.AUTOTUNE)\n",
    " ds = ds.shuffle(buffer_size=batch_size * 10)\n",
    " ds = ds.batch(batch_size, drop_remainder=False)\n",
    " ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    " return ds\n",
    "    \n",
    "ds_splits = ['train', 'test', 'validation']\n",
    "datasets = {split: preprocess_dataset(split) for split in ds_splits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b80808b-0a1e-4c41-82de-c4ea4feb13b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For augmenting data\n",
    "# aug_spelling = naw.SpellingAug()\n",
    "# aug_random = naw.RandomWordAug(action='swap')\n",
    "\n",
    "# def iter_augmented_data(ds):\n",
    "#  for x, y in iter(ds.unbatch()):\n",
    "#    x = x.numpy().decode('utf8')\n",
    "#    # Original text.\n",
    "#    yield x, y\n",
    "#    # Replace a random word by misspelling.\n",
    "#    for x_aug in aug_spelling.augment(x, n=2):\n",
    "#      yield x_aug, y\n",
    "#    # Swap two words in input at random.\n",
    "#    for x_aug in aug_random.augment(x, n=2):\n",
    "#      yield x_aug, y\n",
    "\n",
    "# gen_func = lambda: iter_augmented_data(datasets['train'])\n",
    "# ds_train = tf.data.Dataset.from_generator(\n",
    "#    gen_func, output_types=(tf.string, tf.uint8))\n",
    "# ds_train = ds_train.batch(128).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1294001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the tensorflow_hub BERT model experiences an internal data type issue\n",
    "# on both intel and GPU optimized training, we will be using DistilBERT \n",
    "# Also, DistilBERT provides faster inference times\n",
    "\n",
    "# Giving higher sequence lengths than what the original DistilBERT \n",
    "# fine-tuning recommended since we will be taking stories of patients into account\n",
    "preprocessor = keras_nlp.models.DistilBertPreprocessor.from_preset(\n",
    "    \"distil_bert_base_en_uncased\",\n",
    "    sequence_length=128,\n",
    ")\n",
    "encoder = keras_nlp.models.DistilBertBackbone.from_preset(\n",
    "    \"distil_bert_base_en_uncased\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9a8057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dea5ba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "x = preprocessor(txt)\n",
    "x = encoder(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "x = tf.keras.layers.Dropout(0.1)(x)\n",
    "x = tf.keras.layers.Dense(28, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=[txt], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1f74c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "metrics = [tf.keras.metrics.CategoricalAccuracy('accuracy', dtype=tf.float32)]\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "model.compile(optimizer, loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9cb9eee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None,)]                    0         []                            \n",
      "                                                                                                  \n",
      " distil_bert_preprocessor_5  {'token_ids': (None, 128),   0         ['input_5[0][0]']             \n",
      "  (DistilBertPreprocessor)    'padding_mask': (None, 12                                           \n",
      "                             8)}                                                                  \n",
      "                                                                                                  \n",
      " distil_bert_backbone (Dist  (None, None, 768)            6636288   ['distil_bert_preprocessor_5[0\n",
      " ilBertBackbone)                                          0         ][0]',                        \n",
      "                                                                     'distil_bert_preprocessor_5[0\n",
      "                                                                    ][1]']                        \n",
      "                                                                                                  \n",
      " global_average_pooling1d_4  (None, 768)                  0         ['distil_bert_backbone[0][0]']\n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 768)                  0         ['global_average_pooling1d_4[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 28)                   21532     ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 66384412 (253.24 MB)\n",
      "Trainable params: 66384412 (253.24 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88853b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='./tmp/checkpoint',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs/DistilBERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86e7a640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "340/340 - 197s - loss: 2.0782 - accuracy: 0.5166 - val_loss: 1.9009 - val_accuracy: 0.5534 - 197s/epoch - 578ms/step\n",
      "Epoch 2/5\n",
      "340/340 - 180s - loss: 1.6983 - accuracy: 0.5908 - val_loss: 1.9168 - val_accuracy: 0.5573 - 180s/epoch - 528ms/step\n",
      "Epoch 3/5\n",
      "340/340 - 180s - loss: 1.4581 - accuracy: 0.6478 - val_loss: 2.1907 - val_accuracy: 0.5470 - 180s/epoch - 528ms/step\n",
      "Epoch 4/5\n",
      "340/340 - 180s - loss: 1.2226 - accuracy: 0.7153 - val_loss: 2.4219 - val_accuracy: 0.5487 - 180s/epoch - 528ms/step\n",
      "Epoch 5/5\n",
      "340/340 - 180s - loss: 1.0372 - accuracy: 0.7790 - val_loss: 2.8079 - val_accuracy: 0.5365 - 180s/epoch - 528ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(datasets['train'], validation_data=datasets['validation'], \n",
    "                    epochs=EPOCHS, verbose=2, \n",
    "                    callbacks=[model_checkpoint_callback, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "207e8e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints/DistilBERT_GoEmotions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43034658-d69b-4c75-8079-78a9328038ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "output = model.predict([\"I am feeling down because of a death.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8abdd37-78c9-432f-8106-dced75bd3905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(output[0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac1d03c-0dc9-4c68-9515-d4ad5d4d988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor(X_train[:3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
